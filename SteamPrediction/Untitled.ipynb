{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_splits:int，默认3\n",
    "分割数据的份数，至少为2\n",
    "shuffle:布尔，可选\n",
    "分割数据之前是否打乱数据\n",
    "random_state:int，RandomState实例或者None，可选，默认为None\n",
    "当shuffle==True时，使用\n",
    "如果为整数，作为随机数字生成器的种子，生成随机状态\n",
    "如果为随机状态 ，random_state 是随机状态生成器\n",
    "如果为None，随机数字生成器使用np.random\n",
    "\n",
    "作者：下个艾迪见\n",
    "链接：https://www.jianshu.com/p/b999886cf6ae\n",
    "来源：简书\n",
    "简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# 蒸汽预测\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import math\n",
    "import os\n",
    "import seaborn as sns\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from matplotlib import pyplot\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.decomposition import pca\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC,LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "\n",
    "seed = 2018\n",
    "\n",
    "# Stacking\n",
    "####################################################################################    \n",
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, clf in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(clf)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions\n",
    "        print(out_of_fold_predictions.shape)\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)\n",
    "\n",
    "#简单模型融合\n",
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # 遍历所有模型，你和数据\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    # 预估，并对预估结果值做average\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        #return 0.85*predictions[:,0]+0.15*predictions[:,1]\n",
    "        #return 0.7*predictions[:,0]+0.15*predictions[:,1]+0.15*predictions[:,2]\n",
    "        return np.mean(predictions, axis=1)   \n",
    "\n",
    "def load_train_data():\n",
    "    df = pd.read_csv(\"zhengqi_train.txt\", header=0, sep=\"\\s+\")\n",
    "    #print(df.describe())\n",
    "    X = df.drop(columns=[\"target\"])\n",
    "    y = df[\"target\"]\n",
    "    print(\"X shape:\", X.shape)\n",
    "    print(\"y shape\", y.shape)\n",
    "    #X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    #print(\"X_train shape:\", X_train.shape)\n",
    "    #print(\"y_train shape:\", y_train.shape)\n",
    "    #print(\"X_val shape:\", X_val.shape)\n",
    "    #print(\"y_val shape:\", y_val.shape)\n",
    "    #return X_train, X_val, y_train, y_val\n",
    "    return X, y\n",
    "\n",
    "def load_test_data():\n",
    "    df = pd.read_csv(\"zhengqi_test.txt\", header=0, sep=\"\\s+\")\n",
    "    #print(df.describe())\n",
    "    X_test = df\n",
    "    return X_test\n",
    "\n",
    "def build_nn():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=128, activation='linear', input_dim=18))\n",
    "    model.add(Dense(units=32, activation='linear'))\n",
    "    model.add(Dense(units=8, activation='linear'))\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model\n",
    "    \n",
    "def build_model():\n",
    "    svr = make_pipeline(SVR(kernel='linear'))\n",
    "    line = make_pipeline(LinearRegression())\n",
    "    lasso = make_pipeline(Lasso(alpha =0.0005, random_state=1))\n",
    "    ENet = make_pipeline(ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "    KRR1 = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "    KRR2 = KernelRidge(alpha=1.5, kernel='linear', degree=2, coef0=2.5)    \n",
    "    lgbm = lightgbm.LGBMRegressor(learning_rate=0.01, n_estimators=500, num_leaves=31)\n",
    "    xgb = xgboost.XGBRegressor(booster='gbtree',colsample_bytree=0.8, gamma=0.1, \n",
    "                                 learning_rate=0.02, max_depth=5, \n",
    "                                 n_estimators=500,min_child_weight=0.8,\n",
    "                                 reg_alpha=0, reg_lambda=1,\n",
    "                                 subsample=0.8, silent=1,\n",
    "                                 random_state =seed, nthread = 2)\n",
    "    nn = KerasRegressor(build_fn=build_nn, nb_epoch=500, batch_size=32, verbose=2)\n",
    "    return svr, line, lasso, ENet, KRR1, KRR2, lgbm, xgb, nn\n",
    "\n",
    "def rmsle_cv(model=None,X_train_head=None,y_train=None):\n",
    "    n_folds = 5\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=seed).get_n_splits(X_train_head)\n",
    "    rmse= -cross_val_score(model, X_train_head, y_train, scoring=\"neg_mean_squared_error\", cv = kf)\n",
    "    return(rmse)\n",
    "    \n",
    "def main():\n",
    "    #X_train, X_val, y_train, y_val = load_train_data()\n",
    "    print(\"Load data from file......\")\n",
    "    X_train, y_train = load_train_data()\n",
    "    X_test= load_test_data()\n",
    "    #ntrain = len(X_train)\n",
    "    print(\"X_train shape\", X_train.shape)\n",
    "    print(\"X_test shape\", X_test.shape)\n",
    "    print(\"y_train shape\", y_train.shape)\n",
    "    all_data = pd.concat([X_train, X_test])\n",
    "    print(all_data.shape)\n",
    "    print(\"Load done.\")\n",
    "    #数据观察（可视化）\n",
    "    #import seaborn\n",
    "    #seaborn.distplot(y_train)\n",
    "    #plt.show()\n",
    "    #for col in all_data.columns:\n",
    "    #    seaborn.distplot(X_train[col])\n",
    "    #    seaborn.distplot(X_test[col])\n",
    "    #    plt.show()\n",
    "    # 异常值\n",
    "    all_data = all_data.drop([\"V5\", \"V9\", \"V11\", \"V17\", \"V22\", \"V28\"], axis=1)\n",
    "    print(all_data.shape)\n",
    "    #X = X.drop([\"V5\", \"V9\", \"V11\", \"V17\", \"V22\", \"V28\"], axis=1)\n",
    "    #X_test = X_test.drop([\"V5\", \"V9\", \"V11\", \"V17\", \"V22\", \"V28\"], axis=1)\n",
    "    print(\"Drop done.\")\n",
    "    #need_col_list = [\"6\", \"7\", \"8\", \"10\", \"16\", \"21\", \"27\", \"30\", \"31\", \"32\", \"36\"]\n",
    "    #X_train = process_error(X_train, need_col_list)\n",
    "    #X_test = process_error(X_test, need_col_list)\n",
    "    #all_data = process_error(all_data, need_col_list)\n",
    "    # 标准化\n",
    "    from sklearn import preprocessing\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    all_data = pd.DataFrame(scaler.fit_transform(all_data), columns=all_data.columns)\n",
    "    print(\"Scale done.\")\n",
    "    #print(\"缩放后的describe\", all_data.describe())\n",
    "    # 偏态处理\n",
    "    #skewed_feats = all_data.apply(lambda x: skew(x.dropna())).sort_values(ascending=True)\n",
    "    #print(\"\\nSkew in numerical features: \\n\", skewed_feats)\n",
    "    #skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "    #print(skewness.head(15))\n",
    "    #skewness = skewness[abs(skewness) > 0.75]\n",
    "    #print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "    \n",
    "    #from scipy.special import boxcox1p\n",
    "    #skewed_features = skewness.dropna().index\n",
    "    #lam = 0.15\n",
    "    #for feat in skewed_features:\n",
    "        #all_data[feat] += 1\n",
    "    #    all_data[feat] = boxcox1p(all_data[feat], lam)\n",
    "    #all_data = pd.get_dummies(all_data)\n",
    "    #print(all_data.shape)\n",
    "    #X_train = all_data[:ntrain]\n",
    "    #X_test = all_data[ntrain:]\n",
    "    all_data['V0'] = all_data['V0'].apply(lambda x:math.exp(x))\n",
    "    all_data['V1'] = all_data['V1'].apply(lambda x:math.exp(x))\n",
    "    #all_data['V4'] = all_data['V4'].apply(lambda x:math.exp(x))\n",
    "    all_data['V6'] = all_data['V6'].apply(lambda x:math.exp(x))\n",
    "    all_data['V7'] = all_data['V7'].apply(lambda x:math.exp(x))\n",
    "    all_data['V8'] = all_data['V8'].apply(lambda x:math.exp(x))\n",
    "    #all_data['V12'] = all_data['V12'].apply(lambda x:math.exp(x))\n",
    "    #all_data['V16'] = all_data['V16'].apply(lambda x:math.exp(x))\n",
    "    #all_data['V26'] = all_data['V26'].apply(lambda x:math.exp(x))\n",
    "    #all_data['V27'] = all_data['V27'].apply(lambda x:math.exp(x))\n",
    "    all_data[\"V30\"] = np.log1p(all_data[\"V30\"])\n",
    "    #all_data[\"V31\"] = np.log1p(all_data[\"V31\"])\n",
    "    #all_data[\"V32\"] = np.log1p(all_data[\"V32\"])\n",
    "    #y_train = np.exp(y_train)\n",
    "    scaled = pd.DataFrame(preprocessing.scale(all_data), columns = all_data.columns)\n",
    "    X_train = scaled.loc[0:len(X_train)-1]\n",
    "    X_test = scaled.loc[len(X_train):]\n",
    "    print(\"y skew:\", skew(y_train))\n",
    "    print(\"Skewness done.\")\n",
    "    print(\"偏态后的shape\", X_train.shape, X_test.shape, y_train.shape)\n",
    "    #数据观察（可视化）\n",
    "    #import seaborn\n",
    "    #seaborn.distplot(y_train)\n",
    "    #plt.show()\n",
    "    #for col in all_data.columns:\n",
    "    #    seaborn.distplot(X_train[col])\n",
    "    #    seaborn.distplot(X_test[col])\n",
    "    #    plt.show()\n",
    "    #特征选择\n",
    "    from sklearn.feature_selection import VarianceThreshold\n",
    "    from sklearn.feature_selection import SelectKBest\n",
    "    from sklearn.feature_selection import f_regression\n",
    "    #方差\n",
    "    threshold = 0.85\n",
    "    vt = VarianceThreshold().fit(X_train)\n",
    "    # Find feature names\n",
    "    feat_var_threshold = X_train.columns[vt.variances_ > threshold * (1-threshold)]\n",
    "    X_train = X_train[feat_var_threshold]\n",
    "    X_test = X_test[feat_var_threshold]\n",
    "    all_data = pd.concat([X_train, X_test])\n",
    "    print(\"方差后的shape\", all_data.shape)\n",
    "    #单变量\n",
    "    X_scored = SelectKBest(score_func=f_regression, k='all').fit(X_train, y_train)\n",
    "    feature_scoring = pd.DataFrame({\n",
    "            'feature': X_train.columns,\n",
    "            'score': X_scored.scores_\n",
    "        })\n",
    "    head_feature_num = 18\n",
    "    feat_scored_headnum = feature_scoring.sort_values('score', ascending=False).head(head_feature_num)['feature']\n",
    "    X_train_head = X_train[X_train.columns[X_train.columns.isin(feat_scored_headnum)]]\n",
    "    X_scaled = pd.DataFrame(preprocessing.scale(X_train),columns = X_train.columns)\n",
    "    X_test_head = X_test[X_test.columns[X_test.columns.isin(feat_scored_headnum)]]\n",
    "    print(\"单变量选择后的shape\")\n",
    "    #pca_ = pca.PCA(n_components=0.99) #0.95\n",
    "    #pca_.fit(X)\n",
    "    #X = pd.DataFrame(pca_.transform(X))\n",
    "    #print(\"PCA done.\")\n",
    "    print(X_train_head.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_test_head.shape)\n",
    "    print(\"Start training......\")\n",
    "    svr, line, lasso, ENet, KRR1, KRR2, lgbm, xgb, nn = build_model()\n",
    "    train_start=datetime.now()\n",
    "    score = rmsle_cv(svr, X_train_head, y_train)\n",
    "    print(\"SVR 得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "    svr.fit(X_train_head, y_train)\n",
    "    score = rmsle_cv(line, X_train_head, y_train)\n",
    "    print(\"Line 得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "    score = rmsle_cv(lasso, X_train_head, y_train)\n",
    "    print(\"Lasso 得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "    score = rmsle_cv(ENet, X_train_head, y_train)\n",
    "    print(\"ElasticNet 得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "    score = rmsle_cv(KRR2, X_train_head, y_train)\n",
    "    print(\"Kernel Ridge2 得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "    KRR2.fit(X_train_head, y_train)\n",
    "    # =============================================================================\n",
    "    score = rmsle_cv(KRR1,X_train_head, y_train)\n",
    "    print(\"Kernel Ridge1 得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "    # =============================================================================\n",
    "    head_feature_num = 22\n",
    "    feat_scored_headnum = feature_scoring.sort_values('score', ascending=False).head(head_feature_num)['feature']\n",
    "    X_train_head3 = X_train[X_train.columns[X_train.columns.isin(feat_scored_headnum)]]\n",
    "    X_scaled = pd.DataFrame(preprocessing.scale(X_train),columns = X_train.columns)\n",
    "    score = rmsle_cv(xgb,X_train_head3, y_train)\n",
    "    print(\"Xgboost 得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "    xgb.fit(X_train_head, y_train)\n",
    "    # =============================================================================\n",
    "    head_feature_num = 22\n",
    "    feat_scored_headnum = feature_scoring.sort_values('score', ascending=False).head(head_feature_num)['feature']\n",
    "    X_train_head4 = X_train[X_train.columns[X_train.columns.isin(feat_scored_headnum)]]\n",
    "    X_scaled = pd.DataFrame(preprocessing.scale(X_train),columns = X_train.columns)\n",
    "    score = rmsle_cv(lgbm,X_train_head4, y_train)\n",
    "    print(\"LGBM 得分: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))\n",
    "    lgbm.fit(X_train_head, y_train)\n",
    "    # =============================================================================\n",
    "    head_feature_num = 18\n",
    "    feat_scored_headnum = feature_scoring.sort_values('score', ascending=False).head(head_feature_num)['feature']\n",
    "    X_train_head5 = X_train[X_train.columns[X_train.columns.isin(feat_scored_headnum)]]\n",
    "    X_scaled = pd.DataFrame(preprocessing.scale(X_train_head5),columns = X_train_head5.columns)\n",
    "    score = rmsle_cv(nn,X_train_head5, y_train)\n",
    "    print(\"NN 得分: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))\n",
    "    nn.fit(X_train_head, y_train)\n",
    "    # =============================================================================\n",
    "    averaged_models = AveragingModels(models = (svr,KRR2,lgbm,nn))\n",
    "    score = rmsle_cv(averaged_models, X_train_head, y_train)\n",
    "    print(\"对基模型集成后的得分: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "    averaged_models.fit(X_train_head, y_train)\n",
    "    #stacking_models = StackingAveragedModels(base_models=(svr,KRR2,nn), meta_model=xgb)\n",
    "    #stacking_models.fit(X_train_head.values, y_train.values)\n",
    "    #stacked_train_pred = stacking_models.predict(X_train_head)\n",
    "    #score = mean_squared_error(y_train.values, stacked_train_pred)\n",
    "    #print(\"Stacking Averaged models predict score: {:.4f}\".format(score))\n",
    "    \n",
    "    train_end=datetime.now()\n",
    "    print('spend time:'+ str((train_end-train_start).seconds)+'(s)')\n",
    "\n",
    "    print(\"Predict......\")\n",
    "    #X_test = pd.DataFrame(pca_.transform(X_test))\n",
    "    #X_test = pd.DataFrame(scaler.fit_transform(X_test), columns=X_test.columns)\n",
    "    y_pred = averaged_models.predict(X_test_head)\n",
    "    result = pd.DataFrame(y_pred)\n",
    "    result.to_csv(\"result(averaged_test_).txt\", index=False, header=False)\n",
    "    print(\"Predict Done.\")\n",
    "    print(datetime.now())\n",
    "    \n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
